# Optimierung

\providecommand{\diva}[1]{\mathrm{d} #1}
<!-- \DeclareMathOperator\diva{d} -->

Einige Optimierungsprobleme haben wir schon kennengelernt und zwar

   * bei der linearen Regression (vgl. besonders Kapitel \@ref(sec-linreg-minimierung)) bei der die Parameter der Ansatzfunktion **bestm&ouml;glich** an die Daten gefittet wurden
   * bei der Hauptkomponentenanalyse (vgl. besonders Kapitel \@ref(sec-PCA-maximierung)) als wir die Hauptrichtungen so ermittelt, dass in ihrer Richtung die Varianz **maximal** wurde.

Hier lag in beiden F&auml;llen ein sogenanntes linear-quadratisches Optimierungsproblem vor, f&uuml;r welche die Existenz der L&ouml;sungen bewiesen werden kann und die mit Methoden aus der linearen Algebra direkt gel&ouml;st werden k&ouml;nnen.

Sogenannte *nichtlineare Optimierungsprobleme* liegen vor, wenn die zu erf&uuml;llenden Ziele wirklich nichtlineare Gleichungen enthalten. Zum Bespiel sind g&auml;ngige Elemente von *Neuronalen Netzen* als 
\begin{equation*}
f(x) = \tanh(a\, x + b)
\end{equation*}
gegeben, mit Parametern $a$, $b$ die aus der Minimierung eines *mean square error* Terms der Form
\begin{equation*}
\frac 1N \sum_{k=1}^N|y_k - \tanh(a\, x_k + b)|^2
\end{equation*}
f&uuml;r gegebene Trainingsdaten $(x_k, y_k)$ bestimmt werden.

Wir sehen, dass die Optimierung ein ganz wesentlicher Teil der *Data Science* ist (und ganz unabh&auml;ngig davon ein eigenes Forschungsgebiet ist und quasi &uuml;berall in der Praxis mittel-- oder unmittelbar benutzt wird).

Nachfolgend ein paar Begriffe aus der Optimierung

 * *glatte Optimierung* -- das Modell beinhaltet ausreichend stetige (bzw. differenzierbare) Funktionen. Ein Optimum k&ouml;nnte durch Bestimmung von Ableitungen berechnet werden.
 * *nichtglatte Optimierung* -- das Modell beinhaltet Teile, die nicht differenzierbar sind. Das kann am Problem selbst liegen oder, was bei *machine learning* im Speziellen und *Data Science* an sich eine Rolle spielt, dass die Daten verrauscht sind. Jetzt ist eine (klassische) Ableitung nicht mehr m&ouml;glich aber es existieren diverse Ans&auml;tze zur Abhilfe.
 * *diskrete Optimierung* -- in obigen F&auml;llen sind wir implizit davon ausgegangen, dass die L&ouml;sung und die Gleichungen auf den reellen oder komplexen Zahlen leben. Denkbar ist aber auch, dass diskrete L&ouml;sungen (z.B. Anzahlen oder bin&auml;re Zust&auml;nde) gesucht werden.
 * *kombinatorische Optimierung* -- hier ergeben sich die m&ouml;glichen L&ouml;sungen als Kombination von M&ouml;glichkeiten. Oft ist die Anzahl m&ouml;glicher L&ouml;sungen endlich aber sehr gro&szlig;.
 * *restringierte Optimierung* -- zus&auml;tzlich zu einem Optimalit&auml;tskriterium sind noch Nebenbedingungen zu erf&uuml;llen.

Hier werden wir uns erstmal mit glatter Optimierung ohne Nebenbedingungen besch&auml;ftigen.

## Multivariable Funktionen

Um unsere Optimierungsprobleme in allgemeiner Form zu formulieren und auch um allgemeine L&ouml;sungsans&auml;tze herzuleiten, brauchen wir erstmal ein paar Begriffe aus der Analysis von multivariablen Funktionen.

Es sei also eine Funktion
\begin{equation*}
f\colon \mathbb R^{n}\to \mathbb R^{}, \quad f \colon (x_1,x_2, \dots, x_n) \mapsto f(x_1, x_2, \dotsc, x_n)
\end{equation*}
gegeben, die ein $n$-tupel von Variablen auf einen reellen Wert abbildet. Ein Beispiel w&auml;re
\begin{equation*}
g(x_1, x_2, x_3) = \sin(x_1) + x_3\cos(x_2) + x_1^2 x_2^2 x_3^2 - 2x_2.
\end{equation*}

::: {#variablen-namen .JHSAYS data-latex=''}
Hier verwenden wir jetzt $x_i$ f&uuml;r die $i$-te Variable der multivariablen Funktion. Bitte nicht verwechseln mit der Bezeichnung f&uuml;r den $i$-ten Datenpunkt zum Beispiel in Kapitel \@ref(sec-lineare-regression).

Au&szlig;erdem w&auml;re es besser wir w&uuml;rden die Funktion mit einem Definitionsbereich $D(f)$ angeben, also schreiben
\begin{equation*}
f\colon D(f) \subset \mathbb R^{n}\to \mathbb R^{}
\end{equation*}
da eine Funktion eventuell nicht &uuml;berall definiert ist (bzw. definiert sein muss). Im Sinne der besseren Lesbarkeit, ersparen wir uns dieses Detail.
:::

## Partielle Ableitungen und der Gradient

Wenn wir alle Variablen bis auf die $i$-te f&uuml;r einen Augenblick einfrieren (also auf einen konstanten Wert $\bar x_j$ festlegen und nicht ver&auml;ndern), k&ouml;nnen wir die Teilfunktion 
\begin{equation*}
\bar f_{(i)}\colon \mathbb R^{}\to \mathbb R^{}, \quad \bar f_{(i)}\colon x_i \to f(\bar x_1, \dotsc, \bar x_{i-1}, x_i, \bar x_{i+1}, \dotsc, \bar x_n)
\end{equation*}
als Funktion mit einer Ver&auml;nderlichen (und $n-1$ Parametern) betrachten und wie gehabt ableiten. Die erhaltene, sogenannte *partielle Ableitung* h&auml;ngt von den Parametern $\bar x_j$ ab und wird mit
\begin{equation*}
\frac{\partial f}{\partial x_i}
\end{equation*}
bezeichnet. Alle $n$ m&ouml;glichen partiellen Ableitungen in einen Vektor geschrieben ergeben den sogenannten *Gradienten*
\begin{equation*}
\nabla f = 
\begin{bmatrix}
\frac{\partial f}{\partial x_1} \\
\frac{\partial f}{\partial x_2} \\
\vdots \\
\frac{\partial f}{\partial x_n}
\end{bmatrix}
\colon \mathbb R^{n} \to \mathbb R^{n},
\end{equation*}
der wiederum eine (vektorwertige) Funktion von $n$ Variablen ist.
F&uuml;r unser obiges Beispiel bekommen wir
\begin{equation*}
\nabla g(x_1, x_2, x_3) =
\begin{bmatrix}
\cos(x_1)+2x_1x_2^2x_3^2\\
-x_3\sin(x_2) + x_1^2x_2x_3^2 - 2 \\
\cos(x_2) + 2x_1^2x_2^2x_3
\end{bmatrix}
\end{equation*}

## Richtungs-Ableitung

Die Betrachtung der Funktionen $\bar f_{(i)}$ erm&ouml;glicht die Analysis des Verhaltens der Funktion entlang der $i$-ten Koordinaten Richtung. Um die Funktion in einer beliebigen Richtung um einen festen Punkt 
\begin{equation*}
\bar x = (\bar x_1, \bar x_2, \dotsc, \bar x_n)
\end{equation*}
zu untersuchen, kann die Funktion entlang einer Richtung $v \in \mathbb R^{n}$ parametrisiert werden:
\begin{equation*}
\bar f_{(v)} \colon \mathbb R^{} \to \mathbb R^{}, \quad t \mapsto \bar f_{(v)}(t) = f(\bar x + tv)
\end{equation*}

::: {#richtung-is-partiell .JHSAYS data-latex=''}
F&uuml;r $v=e_i$ bekommen wir direkt, dass $\bar f_{(v)}=\bar f_{(i)}$.
:::

Wiederum handelt es sich um eine reelle Funktion in einer Variablen (hier der Parameter $t$), die wir schulbuchm&auml;&szlig;ig ableiten k&ouml;nnten. F&uuml;r diese sogenannte *Richtungsableitung* gilt der folgende Zusammenhang^[Das folgt aus der Kettenregel f&uuml;r multivariable Funktionen, die wir in der Vorlesung *Mathematik f&uuml;r Data Science 2* noch beweisen werden]
\begin{equation*}
\frac{\diva \bar f_{(v)}}{\diva t}(0) = \sum_i^n \frac{\partial f}{\partial x_i}(\bar x_i) v_i = \langle \nabla f(\bar x), v \rangle
\end{equation*}

::: {#richtung-ableitung .JHSAYS data-latex=''}
Die Ver&auml;nderungsrate der Funktion $f$ im Punkt $\bar x$ in der Richtung von $v$ ist gleich dem Skalarprodukt aus Gradient im Punkt $\bar x$ und der gew&auml;hlten Richtung.
:::

Sei nun $v$ normiert, also $\|v\|=1$, dann gilt nach der Winkelformel, dass 
\begin{equation*}
\langle \nabla f(\bar x), v \rangle = \|\nabla f(\bar x) \| \cos (\alpha)
\end{equation*}
wobei $\alpha$ der von $\nabla f(\bar x)$ und $v$ eingeschlossene Winkel ist. Wir bemerken, dass die Ver&auml;nderung maximal wird, wenn $\alpha = 0$ oder 
\begin{equation*}
v = \frac{1}{ \| \nabla f(\bar x) \| } \nabla f(\bar x)
\end{equation*}
als ein Vielfaches des Gradientenvektors gew&auml;hlt wird.
Andersherum k&ouml;nnen wir einige ganz wesentliche Aspekte folgern:

 * der Gradient selbst in die Richtung des st&auml;rksten Anstiegs
 * der negative Gradient $-\nabla f(\bar x)$ zeigt in die Richtung des st&auml;rksten Abfalls
 * ist der Gradient der Nullvektor, dann findet keine Ver&auml;nderung mehr statt, d.h. dass aus $\nabla f(\bar x) =0$ folgt, dass $\bar x$ ein kritischer Punkt von $f$ ist 
 * ist der Gradient nicht der Nullvektor, kann $\bar x$ kein Minimum und kein Maximum sein (weil die Funktion in $-\nabla f(\bar x)$ Richtung abf&auml;llt und in $\nabla f(\bar x)$ Richtung ansteigt)

## Optimierung

Ganz allgemein k&ouml;nnen wir unsere bisherigen Optimierungsprobleme schreiben als
\begin{equation*}
f(x) \to \min_{x\in \mathbb R^{n}}
\end{equation*}

 * allgemeine Darstellung
   * multivariable Funktion
 * Gradient/Hesse Matrix
 * Gradientenabstiegsverfahren
   * klassisch
   * gedaempft
   * stochastisch

## Optimierung unter Nebenbedingungen

## What's more

 * Automatisches Differenzieren
 * Multikriterielle Optimierung

## Aufgaben

### Numerische Berechnung des Gradienten (P+T)

Berechnen sie n&auml;herungsweise den Gradienten der Beispielfunktion 
\begin{equation*}
f(x_1, x_2, x_3) = \sin(x_1) + x_3\cos(x_2) + x_1x_2x_3 - 2x_2 + x_1^2 + x_2^2 + x_3^2
\end{equation*}
(**Achtung** dieses $f$ ist nur fast das $g$ wie oben)
im Punkt $(x_1, x_2, x_3) = (1, 1, 1)$, 
indem sie die partiellen Ableitungen durch den Differenzenquotienten, z.B.,
\begin{equation*}
\frac{\partial g}{\partial x_2}(1, 1, 1) \approx \frac{g(1, 1+h, 1) - g(1, 1,1)}{h}
\end{equation*}
f&uuml;r $h\in\{10^{-3}, 10^{-6}, 10^{-9}, 10^{-12}\}$ berechnen. Berechnen sie auch die Norm der Differenz zum exakten Wert von $\nabla g(1, 1, 1)$ (s.o.) und interpretieren sie die Ergebnisse.

```{.py}
import numpy as np
 
def gfun(x):
    return np.sin(x[0]) + x[2]*np.cos(x[1]) \
        + x[0]*x[1]*x[2] \
        - 2*x[1] + x[0]**2 + x[1]**2 \
        + x[2]**2

def gradg(x):
    return np.array([np.NaN,
                     -x[2]*np.sin(x[1]) + x[0]*x[2] - 2 + 2*x[1],
                     np.NaN]).reshape((3, 1))


# Inkrement
h = 1e-3

# der x-wert und das h-Inkrement in der zweiten Komponente
xzero = np.ones((3, 1))
xzeroh = xzero + np.array([0, h, 0]).reshape((3, 1))

# partieller Differenzenquotient
dgdxtwo = 1/h*(gfun(xzeroh) - gfun(xzero))
# Alle partiellen Ableitungen ergeben den Gradienten
hgrad = np.array([np.NaN, dgdxtwo, np.NaN]).reshape((3, 1))

# Analytisch bestimmter Gradient
gradx = gradg(xzero)

# Die Differenz in der Norm
hdiff = np.linalg.norm((hgrad-gradx)[1])
# bitte alle Kompenenten berechnen
# und dann die Norm ueber den ganzen Vektor nehmen

print(f'h={h:.2e}: diff in gradient {hdiff.flatten()[0]:.2e}')
```

### Optimierung ohne Gradienten (P+T)

Werten sie $g$ an $1000$ zuf&auml;llig gew&auml;hlten Punkten aus und lokalisieren sie das $\bar x \in \mathbb R^{3}$ an welchem $g$ in diesem Sample den kleinsten Wert annimmt.

&Uuml;berlegen Sie sich eine m&ouml;gliche Verbesserung dieses rein auf Zufall basierenden Verfahrens. Wer Inspiration braucht, kann mal nach *Generischen Algorithmen* suchen.

### Gradientenabstiegsverfahren (P)

Implementieren Sie ein Gradientenabstiegsverfahren mit *line search* durch Bisektion und berechnen Sie ein Minimum von $g$ damit.

```{.py}
import numpy as np

from loesung_5_1 import gfun, gradg


def min_by_btls(func, v=None, curx=None,
                azero=10., tau=.8, c=.9, maxiter=200):
    ''' find a smaller value of f in the direction

    f(x+s*v)

    for s in [0, azero]
    by backtracking linesearch

    https://en.wikipedia.org/wiki/Backtracking_line_search
    '''

    m = -v.T.dot(v)
    cstep = azero
    t = -c*m

    cval = func(curx)

    for kkk in range(maxiter):
        newx = curx+cstep*v
        if cval - func(newx) >= cstep*t:
            return newx
        else:
            cstep = tau*cstep
    raise UserWarning('no smaller value could be found')
    return


def gradienten_abstieg_linesearch(func=None, grad=None, inix=None,
                                  maxiter=100, grad_tol=1e-6):
    '''sucht ein Minimum einer Funktion `func` durch
     * Evaluieren des Gradienten `grad`
     * und anpassen von `inix` in Richtung von `-grad`
     * mit einem `line search Verfahren`
    '''

    # initialisierung
    curx = inix
    for kkk in range(maxiter):
        # compute the current gradient
        # finde ein neues `newx` in -Gradienten Richtung
        # check ob der Gradient unter der Toleranz ist
        # anderenfalls:
        curx = newx  # naechster Iterationschritt

    print(f'max iter {maxiter} reached -- size of grad {nrmcgrd:.2e}')
    return newx

# Startwert
xzero = np.ones((3, 1))

minx = gradienten_abstieg_linesearch(func=gfun, grad=gradg, inix=xzero)

print(f'found minimum f(x) = {gfun(minx)}')
print('at x = ', minx)
```

### Built-in Optimierung in Scipy (P)

1. Benutzen sie die [`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize) Routine um ein Minimum von $g$ zu finden und messen Sie die Zeit die der Algorithmus braucht.

2. Geben Sie dem Algorithmus eine Funktion mit, die den Gradienten berechnet. Berechnen sie ein Minimum und vergleichen Sie die ben&ouml;tigte Zeit.

