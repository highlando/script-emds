# Optimierung unter Nebenbedingungen

Oftmals werden an die gesuchte L&ouml;sung $x^* \in \mathbb R^{n}$ eines Optimierungsproblems a-priori bestimmte Anforderungen gestellt, wie:

 * $x_1 + x_2 \geq 0$ (die L&ouml;sung soll in einem bestimmten Abschnitt liegen)
 * $x_1^2 + x_2*2 - c^2 = 0$ (die ersten beiden Komponenten der L&ouml;sung sollen auf einer Kreisbahn liegen)

Allgemein l&auml;sst sich so ein Optimierungsproblem schreiben als

::: {.definition name="Optimierungsproblem mit Nebenbedingungen"}
\begin{equation*}
f(x) \to \min_{x\in \mathbb R^{n}}, \quad \text{s.t.} \quad g_i(x)\geq 0, \quad h_j(x) = 0,
\end{equation*}

 * mit der *Zielfunktion* $f\colon \mathbb R^{n} \to \mathbb R^{}$
 * und zus&auml;tzlichen Nebenbedingungen (*s.t.* -- *subject to*), die in

   * *Ungleichungsform* &uuml;ber Funktionen $g_i\colon \mathbb R^{n} \to \mathbb R$, mit $i$ aus der Indexmenge $\mathcal I \subset \mathbb N$ oder
   * *Gleichungsform* &uuml;ber Funktionen $h_j\colon \mathbb R^{n} \to \mathbb R$, mit $j$ aus der Indexmenge $\mathcal J \subset \mathbb N$ 
   vorliegen k&ouml;nnen. 


hei&szlig;t *restringiertes Optimierungsproblem* oder *Optimierungsproblem mit Nebenbedingungen*

Liegen keine Gleichheits-- oder keine Ungleichungsnebenbedingungen vor, setzen wir $\mathcal I = \emptyset$ oder $\mathcal J = \emptyset$.

Ein Optimierungsproblem ohne Nebenbedingungen hei&szlig;t auch *unrestringiertes* Problem.

:::

Jetzt stellt sich zur Frage ob ein $x^*$ *optimal* ist, noch die Frage, ob es auch *zul&auml;ssig* (engl.: *feasible*) ist. Dazu l&auml;sst sich formal der Zul&auml;ssigkeitsbereich (engl.: *feasible set*) definieren
\begin{equation*}
\Omega = \{x\in \mathbb R^{n} ~|~g_i(x)\geq 0, \quad h_j(x)=0, \quad i\in \mathcal I,\, j\in \mathcal J\}
\end{equation*}
und das Optimierungsproblem als
\begin{equation*}
f(x) \to \min_{x\in \Omega}
\end{equation*}
schreiben.

::: {#constaints-domofdef .JHSAYS data-latex=''}
Die Definition \@ref(def:loc-glob-minimum) einer Minimalstelle gilt unmittelbar weiter, wenn nun auch der Zul&auml;ssigkeitsbereich noch beachtet wird.
:::

Die Unterscheidung von $D(f)$ und $\Omega$ in der Betrachtung des Optimierungsproblems und potentieller Minimalstellen hat diverse vor allem praktische Gr&uuml;nde:

 * der Definitionsbereich von $f$ ist eine vorgegebene Eigenschaft der Funktion w&auml;hrend $\Omega$ vielleicht variiert werden soll
 * liegen nichttriviale Gleichheitsbedingungen vor, ist beispielsweise kein Punkt von $\Omega$ mehr ein innerer Punkt (im $\mathbb R^{n}$) und der Gradient von $f$ w&auml;re erstmal nicht definiert
 * die Modellierung ist oftmals einfacher, wenn Nebenbedingungen einfach zum Problem hinzugef&uuml;gt werden k&ouml;nnen
 * ebenso die Feststellung ob ein gegebener Punkt im Zul&auml;ssigkeitsbereich liegt

Die Analysis restringierter Optimierungsprobleme und entsprechend die Umsetzung von Algorithmen zur L&ouml;sung wird durch die Nebenbedingungen ungleich schwieriger, da

 * in der Theorie nicht mehr einfach differenziert werden kann (insbesondere bei Gleichheitsbedingungen oder wenn der kritische Punkt am Rand der Ungleichungsbedingungen liegt) und
 * in der Umsetzung auf dem Computer darauf geachtet werden muss, dass der Zul&auml;ssigkeitsbereich nicht verlassen wird.

## Richtungen und Nebenbedingungen

Bei *restringierten Optimierungsproblemen* ist die Richtung in der analysiert wird entscheidend. Hierbei geht es darum ob in einer Richtung $v$

1. die Zielfunktion eventuell kleiner wird
2. der Zul&auml;ssigkeitsbereich eventuell verlassen wird (bspw. charakterisiert durch $g(x) = 0$ oder $h(x)\geq0$)

Da es stets nur um die unmittelbare Umgebung eines Punktes geht, und wir aus der Diskussion der Ableitung (in 1D) wissen, dass eine differenzierbare Funktion lokal gut durch ihre Tangente angen&auml;hert werden kann^[*gut* im Sinne von der Fehler $f(x+h)-f(x)-f'(x)h$ geht schneller zur $0$ als $h$], k&ouml;nnen wir beide Betrachtungen in der *lineaeren Approximation* anstellen.

Wir schauen also ob f&uuml;r eine Richtung $v$ gilt, ob nicht 

1. $f(x^*) > f(x^*+hv) \approx f(x^*) + \nabla f(x^*)^Tv$ bzw.
2. $0 \neq g(x^*+hv) \approx \nabla g(x^*)^Tv$ oder $0>h(x^*+hv) \approx \nabla h(x^*)^Tv$.

## Restringierte Optimierungsprobleme und der Gradient

Zur Illustration und zur Einf&uuml;hrung der Konzepte betrachten wir Probleme, die entweder nur Gleichungsnebenbedingungen oder nur Ungleichungsnebenbedingungen haben. 

Wir beginnen mit Gleichungsnebenbedingungen und das auch nur im zweidimensionalen Fall:
\begin{equation*}
f(x,y) \to \min, \quad \text{s.t. }g(x,y)=c.
\end{equation*}
Aus der schematischen Darstellung in Abbildung \@ref(fig:eqconstraint-opti) k&ouml;nnen wir ablesen, dass in einem potentiellen Extremum, die Gradienten von $f$ und $g$ in die gleiche Richtung zeigen, es also eine Skalar $\lambda$ geben muss, sodass in einem kritischen Punkt $(x^*, y^*)$ gilt, dass
\begin{equation*}
\nabla f(x^*, y^*) + \lambda \nabla g(x^*, y^*) =0
\end{equation*}

```{r eqconstraint-opti, echo=FALSE, fig.show='hold', fig.cap='Schematische Darstellung eines Optimierungsproblems mit Gleichungsnebenbedingungen in 2D.', out.width='60%', fig.asp=.75, fig.align='center'}
knitr::include_graphics(c("bilder/08-LagrangeMultipliers2D.png"))
```

Wir k&ouml;nnten also versuchen, eine L&ouml;sung $(x,y,\lambda)$ f&uuml;r das Gleichungssystem
\begin{align*}
\nabla f(x, y) + \lambda \nabla g(x, y) &=0 \\
g(x,y) &= c
\end{align*}
zu finden.

::: {#lagrange-KKT .JHSAYS data-latex=''}
Dieses Gleichungssystem ist ein Spezialfall der *Karush-Kuhn-Tucker* Bedingungen, die ein notwendiges Kriterium f&uuml;r einen optimalen Punkt darstellen. Das involvierte $\lambda$ wird *Lagrange Multiplikator* genannt.
:::

Dass an einem potentiellen Minimum gelten muss, dass $\nabla f(x^*) = -\lambda \nabla g(x^*)$ haben wir anhand einer Zeichnung im 2D Fall festgestellt. 

F&uuml;r $x\in \mathbb R^{n}$ und einer Gleichungsnebenbedingung $g$, ist die Argumentation wie folgt.

::: {#not-para-not-min .lemma}
Sei $x^*\in \mathbb R^{n}$ mit $g(x^*)=0$ so, dass $\nabla f$ und $\nabla g$ **nicht** parallel sind. Dann gilt f&uuml;r die Richtung
\begin{equation*}
v := -\biggl (I-\frac{1}{\|\nabla g(x^*)\|^2}\nabla g(x^*)g(x^*)^T \biggr )\nabla f(x^*)
\end{equation*}
dass $\nabla g(x^*)^Tv=0$ und $\nabla f(x^*)^Tv<0$ ist.
:::

Lemma \@ref(lem:not-para-not-min) sagt, dass es im skizzierten Fall also eine Richtung gibt, in der (in erster Ableitung) die Funktion $f$ minimiert werden kann ohne den Zul&auml;ssigkeitsbereich zu verlassen.

## Linear Quadratische Probleme

Ist die Zielfunktion als quadratische Funktion
\begin{equation*}
f(x) = x^T Q x + c^Tx 
\end{equation*}
gegeben mit $Q\in \mathbb R^{n\times n}$ und $c\in \mathbb R^{n}$ und sind die Nebenbedingungen linear gegeben als
\begin{equation*}
Ax \geq b
\end{equation*}
mit $A\in \mathbb R^{m\times n}$, $b\in \mathbb R^{m}$ und mit $Ax \geq b$ bedeuten soll, dass **alle Eintr&auml;ge** des Vektors $Ax-b$ kleiner oder gleich $0$ sind, dann sprechen wir von einem (linearen) quadratischen Optimierungsproblem.

Hier m&uuml;ssen Gleichheitsbedingungen nicht explizit angef&uuml;hrt werden, da sie durch Ungleichungsbedingungen ausgedr&uuml;ckt werden k&ouml;nnen (vgl. $x=0$ gdw. $x\geq0$ und $-x\geq 0$).

Sind allerdings alle Bedingungen letztlich Gleichheitsbedingungen, liegt also das Problem als
\begin{equation*}
x^T Q x + c^Tx  \to \min_{x\in \mathbb R^{n}} \quad \text{s.t. }Ax=b
\end{equation*}
vor, dann sind die notwendigen Optimalit&auml;tsbedingungen durch
\begin{equation*}
\begin{bmatrix}
Q & A^T \\
A & 0
\end{bmatrix}
=
\begin{bmatrix}
-c \\ b
\end{bmatrix}.
\end{equation*}

Aus der Betrachtung dieser Optimalit&auml;tsbedingungen k&ouml;nnen wir folgern, dass, wenn $Q$ symmetrisch ist und positiv definit, 
sowie alle Zeilen von $A$ linear unabh&auml;ngig sind, dass dann das Optimierungsproblem eine eindeutige L&ouml;sung hat, die durch die Optimalit&auml;tsbedingungen eindeutig charakterisiert ist.

## Sequential Quadratic Programming

Aus der Beobachtung, dass wir LQP Probleme direkt mit $Q$ symmetrisch positiv definit direkt l&ouml;sen k&ouml;nnen und dass wir f&uuml;r kleine Abweichungen $h=x^*-x \in \mathbb R^{n}$ multivariable Funktionen &uuml;ber quadratische (f&uuml;r unser $f$) und lineare Approximationen (f&uuml;r unsere $g_i$) gut ann&auml;hern k&ouml;nnen:
\begin{equation*}
f(x^*) = f(x+h) = f(x) + \nabla f(x)^T h + h^TH_f(x) h + \mathcal o(\| h \| ^2 )
\end{equation*}
und
\begin{equation*}
g_i(x^*) = g_i(x+h) = g_i(x) + \nabla g_i(x)^T h + \mathcal o(\| h \|), \quad i \in \mathcal I,
\end{equation*}
ergibt sich das iterative Verfahren aus einer N&auml;herungsl&ouml;sung $x_k$ eine Verbesserung $x_{k+1}$ als L&ouml;sung des LQP Problems
\begin{equation*}
x^T Q_k x + c_k^Tx  \to \min_{x\in \mathbb R^{n}} \quad \text{s.t. }A_kx=b_k
\end{equation*}
zu berechnen, wobei
\begin{equation*}
Q_k=H_f(x_k), \quad c_k=\nabla f(x_k)
\end{equation*}
und
\begin{equation*}
A_k = 
\begin{bmatrix}
\nabla g_i(x_k) 
\end{bmatrix}_{i \in \mathcal I} \in \mathbb R^{|\mathcal I| \times n},
\quad 
b_k = -
\begin{bmatrix}
g_i(x_k) 
\end{bmatrix}_{i \in \mathcal I}\in \mathbb R^{|\mathcal I|}.
\end{equation*}

::: {#rem-conv-hesse .JHSAYS data-latex=''}
Ist die Funktion $f$ konvex und zweimal stetig differenzierbar (in einer Umgebung von $x_k$), dann ist $H_f(x_k)$ positiv definit und das LQP hat eine eindeutitge L&ouml;sung $x_{k+1}$.
:::

## Aufgaben

### KKT f&uuml;r LQP (T)

Verifizieren Sie, dass die notwendigen Optimalit&auml;tsbedingungen f&uuml;r das LQP Problem mit Gleichungsnebenbedingungen (mit $m=1$) genau der Optimalit&auml;sbedingung "$\nabla f = \lambda \nabla g$" entspricht.

### Nicht parallele Gradienten (T)

Verifizieren sie die Aussage aus Lemma \@ref(lem:not-para-not-min).

### Hauptkomponente aus SQP (T+P)

Skizzieren einen SQP-Schritt des Optimierungsproblem, das die erste Hauptkomponentenrichtung definiert.

Implementieren sie die SQP Iteration zur Berechnung der ersten Hauptkomponentenrichtung f&uuml;r die Pinguin Daten. Berechnen Sie den Fehler zur *exakten* (mit der SVD berechneten) L&ouml;sung und geben sie ihn in jedem Schritt aus.




