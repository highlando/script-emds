# Optimierung unter Nebenbedingungen

Oftmals werden an die gesuchte L&ouml;sung $x^* \in \mathbb R^{n}$ eines Optimierungsproblems a-priori bestimmte Anforderungen gestellt, wie:

 * $x_1 + x_2 \geq 0$ (die L&ouml;sung soll in einem bestimmten Abschnitt liegen)
 * $x_1^2 + x_2^2 - c^2 = 0$ (die ersten beiden Komponenten der L&ouml;sung sollen auf einer Kreisbahn liegen)

Allgemein l&auml;sst sich so ein Optimierungsproblem schreiben als

::: {.definition name="Optimierungsproblem mit Nebenbedingungen"}
\begin{equation*}
f(x) \to \min_{x\in \mathbb R^{n}}, \quad \text{s.t.} \quad g_i(x)\geq 0, \quad h_j(x) = 0,
\end{equation*}

 * mit der *Zielfunktion* $f\colon \mathbb R^{n} \to \mathbb R^{}$
 * und zus&auml;tzlichen Nebenbedingungen (*s.t.* -- *subject to*), die in

   * *Ungleichungsform* &uuml;ber Funktionen $g_i\colon \mathbb R^{n} \to \mathbb R$, mit $i$ aus der Indexmenge $\mathcal I \subset \mathbb N$ oder
   * *Gleichungsform* &uuml;ber Funktionen $h_j\colon \mathbb R^{n} \to \mathbb R$, mit $j$ aus der Indexmenge $\mathcal J \subset \mathbb N$ 
   vorliegen k&ouml;nnen. 


hei&szlig;t *restringiertes Optimierungsproblem* oder *Optimierungsproblem mit Nebenbedingungen*

Liegen keine Gleichheits-- oder keine Ungleichungsnebenbedingungen vor, setzen wir $\mathcal I = \emptyset$ oder $\mathcal J = \emptyset$.

Ein Optimierungsproblem ohne Nebenbedingungen hei&szlig;t auch *unrestringiertes* Problem.

:::

Jetzt stellt sich zur Frage ob ein $x^*$ *optimal* ist, noch die Frage, ob es auch *zul&auml;ssig* (engl.: *feasible*) ist. Dazu l&auml;sst sich formal der Zul&auml;ssigkeitsbereich (engl.: *feasible set*) definieren
\begin{equation*}
\Omega = \{x\in \mathbb R^{n} ~|~g_i(x)\geq 0, \quad h_j(x)=0, \quad i\in \mathcal I,\, j\in \mathcal J\}
\end{equation*}
und das Optimierungsproblem als
\begin{equation*}
f(x) \to \min_{x\in \Omega}
\end{equation*}
schreiben.

::: {#constaints-domofdef .JHSAYS data-latex=''}
Die Definition \@ref(def:loc-glob-minimum) einer Minimalstelle gilt unmittelbar weiter, wenn nun auch der Zul&auml;ssigkeitsbereich noch beachtet wird.
:::

Die Unterscheidung von $D(f)$ und $\Omega$ in der Betrachtung des Optimierungsproblems und potentieller Minimalstellen hat diverse vor allem praktische Gr&uuml;nde:

 * der Definitionsbereich von $f$ ist eine vorgegebene Eigenschaft der Funktion w&auml;hrend $\Omega$ vielleicht variiert werden soll
 * liegen nichttriviale Gleichheitsbedingungen vor, ist beispielsweise kein Punkt von $\Omega$ mehr ein innerer Punkt (im $\mathbb R^{n}$) und der Gradient von $f$ w&auml;re erstmal nicht definiert
 * die Modellierung ist oftmals einfacher, wenn Nebenbedingungen einfach zum Problem hinzugef&uuml;gt werden k&ouml;nnen
 * ebenso die Feststellung ob ein gegebener Punkt im Zul&auml;ssigkeitsbereich liegt

Die Analysis restringierter Optimierungsprobleme und entsprechend die Umsetzung von Algorithmen zur L&ouml;sung wird durch die Nebenbedingungen ungleich schwieriger, da

 * in der Theorie nicht mehr einfach differenziert werden kann (insbesondere bei Gleichheitsbedingungen oder wenn der kritische Punkt am Rand der Ungleichungsbedingungen liegt) und
 * in der Umsetzung auf dem Computer darauf geachtet werden muss, dass der Zul&auml;ssigkeitsbereich nicht verlassen wird.

## Richtungen und Nebenbedingungen

Bei *restringierten Optimierungsproblemen* ist die Richtung in der analysiert wird entscheidend. Hierbei geht es darum ob in einer Richtung $v$

1. die Zielfunktion eventuell kleiner wird
2. der Zul&auml;ssigkeitsbereich eventuell verlassen wird (bspw. charakterisiert durch $g(x) = 0$ oder $h(x)\geq0$)

Da es stets nur um die unmittelbare Umgebung eines Punktes geht, und wir aus der Diskussion der Ableitung (in 1D) wissen, dass eine differenzierbare Funktion lokal gut durch ihre Tangente angen&auml;hert werden kann^[*gut* im Sinne von der Fehler $f(x+h)-f(x)-f'(x)h$ geht schneller zur $0$ als $h$], k&ouml;nnen wir beide Betrachtungen in der *lineaeren Approximation* anstellen.

Wir schauen also ob f&uuml;r eine Richtung $v$ gilt, ob nicht 

1. $f(x^*) > f(x^*+hv) \approx f(x^*) + \nabla f(x^*)^Tv$ bzw.
2. $0 \neq g(x^*+hv) \approx \nabla g(x^*)^Tv$ oder $0>h(x^*+hv) \approx \nabla h(x^*)^Tv$.

## Restringierte Optimierungsprobleme und der Gradient

Zur Illustration und zur Einf&uuml;hrung der Konzepte betrachten wir Probleme, die entweder nur Gleichungsnebenbedingungen oder nur Ungleichungsnebenbedingungen haben. 

Wir beginnen mit Gleichungsnebenbedingungen und das auch nur im zweidimensionalen Fall:
\begin{equation*}
f(x,y) \to \min, \quad \text{s.t. }g(x,y)=c.
\end{equation*}
Aus der schematischen Darstellung in Abbildung \@ref(fig:eqconstraint-opti) k&ouml;nnen wir ablesen, dass in einem potentiellen Extremum, die Gradienten von $f$ und $g$ in die gleiche Richtung zeigen, es also eine Skalar $\lambda$ geben muss, sodass in einem kritischen Punkt $(x^*, y^*)$ gilt, dass
\begin{equation*}
\nabla f(x^*, y^*) + \lambda \nabla g(x^*, y^*) =0
\end{equation*}

<div class="figure" style="text-align: center">
<img src="bilder/08-LagrangeMultipliers2D.png" alt="Schematische Darstellung eines Optimierungsproblems mit Gleichungsnebenbedingungen in 2D." width="60%" />
<p class="caption">(\#fig:eqconstraint-opti)Schematische Darstellung eines Optimierungsproblems mit Gleichungsnebenbedingungen in 2D.</p>
</div>

Wir k&ouml;nnten also versuchen, eine L&ouml;sung $(x,y,\lambda)$ f&uuml;r das Gleichungssystem
\begin{equation}
\begin{split}
\nabla f(x, y) + \lambda \nabla g(x, y) &=0 \\
g(x,y) &= c
\end{split}
(\#eq:kkt-sc)
\end{equation}
zu finden.

::: {#lagrange-KKT .JHSAYS data-latex=''}
Dieses Gleichungssystem ist ein Spezialfall der *Karush-Kuhn-Tucker* Bedingungen, die ein notwendiges Kriterium f&uuml;r einen optimalen Punkt darstellen. Das involvierte $\lambda$ wird *Lagrange Multiplikator* genannt.
:::

Dass an einem potentiellen Minimum gelten muss, dass $\nabla f(x^*) = -\lambda \nabla g(x^*)$ haben wir anhand einer Zeichnung im 2D Fall festgestellt. 

F&uuml;r $x\in \mathbb R^{n}$ und einer Gleichungsnebenbedingung $g$, ist die Argumentation wie folgt.

::: {#not-para-not-min .lemma}
Sei $x^*\in \mathbb R^{n}$ mit $g(x^*)=0$ so, dass $\nabla f$ und $\nabla g$ **nicht** parallel sind. Dann gilt f&uuml;r die Richtung
\begin{equation*}
v := -\biggl (I-\frac{1}{\|\nabla g(x^*)\|^2}\nabla g(x^*)g(x^*)^T \biggr )\nabla f(x^*)
\end{equation*}
dass $\nabla g(x^*)^Tv=0$ und $\nabla f(x^*)^Tv<0$ ist.
:::

Lemma \@ref(lem:not-para-not-min) sagt, dass es im skizzierten Fall also eine Richtung gibt, in der (in erster Ableitung) die Funktion $f$ minimiert werden kann ohne den Zul&auml;ssigkeitsbereich zu verlassen.

## Linear Quadratische Probleme

Ist die Zielfunktion als quadratische Funktion
\begin{equation*}
f(x) = x^T Q x + c^Tx 
\end{equation*}
gegeben mit $Q\in \mathbb R^{n\times n}$ und $c\in \mathbb R^{n}$ und sind die Nebenbedingungen linear gegeben als
\begin{equation*}
Ax \geq b
\end{equation*}
mit $A\in \mathbb R^{m\times n}$, $b\in \mathbb R^{m}$ und mit $Ax \geq b$ bedeuten soll, dass **alle Eintr&auml;ge** des Vektors $Ax-b$ kleiner oder gleich $0$ sind, dann sprechen wir von einem (linearen) quadratischen Optimierungsproblem.

Hier m&uuml;ssen Gleichheitsbedingungen nicht explizit angef&uuml;hrt werden, da sie durch Ungleichungsbedingungen ausgedr&uuml;ckt werden k&ouml;nnen (vgl. $x=0$ gdw. $x\geq0$ und $-x\geq 0$).

Sind allerdings alle Bedingungen letztlich Gleichheitsbedingungen, liegt also das Problem als
\begin{equation*}
x^T Q x + c^Tx  \to \min_{x\in \mathbb R^{n}} \quad \text{s.t. }Ax=b
\end{equation*}
vor, dann sind die notwendigen Optimalit&auml;tsbedingungen durch
\begin{equation*}
\begin{bmatrix}
Q+Q^T & A^T \\
A & 0
\end{bmatrix}
=
\begin{bmatrix}
-c \\ b
\end{bmatrix}.
\end{equation*}

Aus der Betrachtung dieser Optimalit&auml;tsbedingungen k&ouml;nnen wir folgern, dass, wenn $Q$ symmetrisch ist und positiv definit, 
sowie alle Zeilen von $A$ linear unabh&auml;ngig sind, dass dann das Optimierungsproblem eine eindeutige L&ouml;sung hat, die durch die Optimalit&auml;tsbedingungen eindeutig charakterisiert ist.

## Sequential Quadratic Programming

Aus der Beobachtung, dass wir LQP Probleme direkt mit $Q$ symmetrisch positiv definit direkt l&ouml;sen k&ouml;nnen und dass wir f&uuml;r kleine Abweichungen $\xi$ von einem gebenen Punkt $x$ multivariable Funktionen &uuml;ber quadratische (f&uuml;r unser $f$) und lineare Approximationen (f&uuml;r unsere $g_i$) gut ann&auml;hern k&ouml;nnen:
\begin{equation*}
f(x^*) = f(x+\xi) = f(x) + \nabla f(x)^T \xi + \xi^TH_f(x) \xi + \mathcal o(\| \xi \| ^2 )
\end{equation*}
und
\begin{equation*}
g_i(x^*) = g_i(x+\xi) = g_i(\xi) + \nabla g_i(\xi)^T h + \mathcal o(\| \xi \|), \quad i \in \mathcal I,
\end{equation*}
ergibt sich das folgende iterative Verfahren genannt *Sequential Linear Programming* (SQP):

Beginnend von einem N&auml;herungswert $x^k$

1. Berechne $d^k$ aus der Minimierung von^[Die korrekte quadratische Approximation von $f$ w&uuml;rde noch den Term $f(x^k)$ enthalten. Dieser kann aber einfach weggelassen werden bei der Suche der Minimalstelle.]
  \begin{align*}
   \tilde f(x^k+d):= \nabla f(x^k)^T d + d^TH_f(x^k) d \to \min_{d\in \mathbb R^{n}}, \\\quad \text{unter der Nebenbedingung} \\ \tilde g_i(x^k+d):=g(x^k)+\nabla g_i(x^k)d = 0 \quad i \in \mathcal I
  \end{align*}
2. ein Update $x^{k+1}=x^k+d^k$.

Es ist also in jeder Iteration ein linear quadratisches Optimierungsproblem 
\begin{equation*}
x^T Q_k x + c_k^Tx  \to \min_{x\in \mathbb R^{n}} \quad \text{s.t. }A_kx=b_k
\end{equation*}
zu l&ouml;sen, wobei (in der obigen Notation mit $Q$, $c$, $A$ und $b$) gilt dass
\begin{equation*}
Q_k=H_f(x^k), \quad c_k=\nabla f(x_k)
\end{equation*}
und
\begin{equation*}
A_k = 
\begin{bmatrix}
\nabla g_i(x_k)^T
\end{bmatrix}_{i \in \mathcal I} \in \mathbb R^{|\mathcal I| \times n},
\quad 
b_k = -
\begin{bmatrix}
g_i(x_k) 
\end{bmatrix}_{i \in \mathcal I}\in \mathbb R^{|\mathcal I|}.
\end{equation*}

::: {#rem-conv-hesse .JHSAYS data-latex=''}
Ist die Funktion $f$ konvex und zweimal stetig differenzierbar (in einer Umgebung von $x_k$), dann ist die Hesse-matrix $H_f(x_k)$ positiv definit und das LQP hat eine eindeutige L&ouml;sung $x_{k+1}$.
:::

## Aufgaben

### KKT f&uuml;r LQP (T)

Verifizieren Sie, dass die notwendigen Optimalit&auml;tsbedingungen f&uuml;r das LQP Problem mit Gleichungsnebenbedingungen (mit $m=1$) genau der Optimalit&auml;sbedingung aus Gleichung \@ref(eq:kkt-sc) entspricht. **Hinweis**: Mit der Definition der *totalen Ableitung* und der Relation zum Gradienten f&uuml;r reellwertige multivariable Funktionen (vgl. die Vorlesung *Mathe f&uuml;r DS2* vom 6. Juli) ist eine Darstellung der Gradienten $\nabla f(x)$ und $\nabla g(x)$ direkt herleitbar.

### Nicht parallele Gradienten (T)

Verifizieren sie die Aussage aus Lemma \@ref(lem:not-para-not-min).

### Hauptkomponente aus SQP (T+P)

Skizzieren sie das Optimierungsproblems, das die **letzte** Hauptkomponentenrichtung definiert (also die Richtung mit minimaler Varianz) eines zentrierten Datensatzes definiert (analog dazu, wie in Abschnitt \@ref(sec-pca-maximierung) eingef&uuml;hrt). **Hinweis**: Alles wird vielleicht etwas einfacher, wenn sie die Nebenbedingung $\|x\|=1$ durch $\|x\|^2 = 1$ bzw. $x^Tx = 1 $ ersetzen. (T)

Skizzieren einen SQP-Schritt zur L&ouml;sung dieses Problems. (T)

Implementieren sie die SQP Iteration zur Berechnung der letzten Hauptkomponentenrichtung f&uuml;r die Pinguin Daten. Berechnen Sie die Abweichung zur *exakten* (mit der SVD berechneten) L&ouml;sung und geben sie ihn in jedem Schritt beispielsweise den Winkel zwischen dem Iteranten und der exakten Loesung berechnen. **Hinweis**: Nur die Norm der Differenz k&ouml;nnte irritieren, weil das Vorzeichen der Richtungen nicht festgelegt ist.

```py
import json
import numpy as np

with open('penguin-data.json', 'r') as f:
    datadict = json.load(f)

data = np.array(datadict['data'])

# center the data
X = data - data.mean(axis=0)
XtX = X.T @ X  # for later use

U, S, Vh = np.linalg.svd(X)

pcfour = Vh[-1:, :].T  # die "letzte" Hauptrichtung
nrmpcf = np.linalg.norm(pcfour)  # brauchen wir um den Winkel zu berechnen

xk = np.zeros((4, 1))  # Startvektor
xk[0] = 1
arccosalpha = xk.T @ pcfour / (np.linalg.norm(xk)*nrmpcf)
print(f'Iteration: {0} -- `arccos(sol, xk)` {arccosalpha}')


def solve_sadpoint_sys_x(Q=None, A=None, fone=None, ftwo=None):
    ''' Loesung des Sattelpunktprobles

    | Q  A.T | . | x |    | f1 |
    | A   0  |   | l |  = | f2 |

    Notes:
    -----

    Es wird nur `x` zurueckgegeben

    '''
    m = A.shape[0]
    lineone = [Q, A.T]
    linetwo = [A, np.zeros((m, m))]
    sdptmat = np.vstack([np.hstack(lineone),
                         np.hstack(linetwo)])
    rhs = np.vstack([fone, ftwo])
    xl = np.linalg.solve(sdptmat, rhs)
    return xl[:-m]  # return only the `x-part`


for kkk in range(1, 11):
    # ...
    # die SQP Iteration
    # ...
    xk = xk + solve_sadpoint_sys_x()

    arccosalpha = xk.T @ pcfour / (np.linalg.norm(xk)*nrmpcf)
    print(f'Iteration: {kkk} -- `arccos(sol, xk)` {arccosalpha}')
```
